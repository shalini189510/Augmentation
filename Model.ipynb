{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1GHfUt3omD5UPVWsYVIJ_JqXjPzyEYhoG","authorship_tag":"ABX9TyMbW+/g5b1HaviIUszYUxzX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vseCkDOINnDF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594543765942,"user_tz":-330,"elapsed":3324,"user":{"displayName":"Shalini Kumari","photoUrl":"https://lh5.googleusercontent.com/-f1p0Rlt5xtw/AAAAAAAAAAI/AAAAAAAAAPg/QAilL7XEoAo/s64/photo.jpg","userId":"00879105127542526832"}},"outputId":"d5077671-9b9c-44c3-a1dc-de902ab236f4"},"source":["import numpy as np\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense, Activation\n","from keras.preprocessing.image import img_to_array\n","from keras.utils import to_categorical\n","import os\n","import cv2\n","\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","from keras.preprocessing import image\n","\n","import argparse\n","import imutils"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EpCA2meLkyvv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594549819757,"user_tz":-330,"elapsed":1465,"user":{"displayName":"Shalini Kumari","photoUrl":"https://lh5.googleusercontent.com/-f1p0Rlt5xtw/AAAAAAAAAAI/AAAAAAAAAPg/QAilL7XEoAo/s64/photo.jpg","userId":"00879105127542526832"}},"outputId":"8c98e618-2389-431e-c6bf-7e9f39fd23ea"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ej-hqAQ3SJ20","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594561734956,"user_tz":-330,"elapsed":2097,"user":{"displayName":"Shalini Kumari","photoUrl":"https://lh5.googleusercontent.com/-f1p0Rlt5xtw/AAAAAAAAAAI/AAAAAAAAAPg/QAilL7XEoAo/s64/photo.jpg","userId":"00879105127542526832"}},"outputId":"99b54ce0-909c-45c0-f12c-134a2988321c"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                 shear_range = 0.2,\n","                 zoom_range = 0.2,\n","                 horizontal_flip = True)\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","\n","training_set = train_datagen.flow_from_directory('/content/drive/My Drive/augmented/image_data/train',\n","                target_size = (128, 128),\n","                batch_size = 32,\n","                class_mode = 'categorical')\n","test_set= test_datagen.flow_from_directory('/content/drive/My Drive/augmented/image_data/validation',\n","                  target_size = (128, 128),\n","                  batch_size = 32,\n","                  class_mode = 'categorical')\n"],"execution_count":74,"outputs":[{"output_type":"stream","text":["Found 2121 images belonging to 3 classes.\n","Found 63 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G2wpuM0MNtUi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594549971004,"user_tz":-330,"elapsed":1689,"user":{"displayName":"Shalini Kumari","photoUrl":"https://lh5.googleusercontent.com/-f1p0Rlt5xtw/AAAAAAAAAAI/AAAAAAAAAPg/QAilL7XEoAo/s64/photo.jpg","userId":"00879105127542526832"}}},"source":["train_dir='/content/drive/My Drive/augmented/image_data/train'\n","test_dir='/content/drive/My Drive/augmented/image_data/validation'\n","\n","\n","\n","train_dir_saree=train_dir+ '/saree'\n","train_dir_saree=train_dir + '/saree'\n","train_dir_men_shrts = train_dir + '/shirt'\n","test_dir_men_shrts = test_dir + '/shirt'\n","train_dir_men_tshrts = train_dir + '/tshirt'\n","test_dir_men_tshrts = test_dir + '/tshirt'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrZXC1fYN6kr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1594549976126,"user_tz":-330,"elapsed":1748,"user":{"displayName":"Shalini Kumari","photoUrl":"https://lh5.googleusercontent.com/-f1p0Rlt5xtw/AAAAAAAAAAI/AAAAAAAAAPg/QAilL7XEoAo/s64/photo.jpg","userId":"00879105127542526832"}},"outputId":"7d1294fd-7e5b-4025-b9fa-1a12ed5c5b16"},"source":["print('number of shirts training images - ',len(os.listdir(train_dir_men_shrts)))\n","print('number of tshirts training images - ',len(os.listdir(train_dir_men_tshrts)))\n","print('number of shirts testing images - ',len(os.listdir(test_dir_men_shrts)))\n","print('number of tshirts testing images - ',len(os.listdir(test_dir_men_tshrts)))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["number of shirts training images -  707\n","number of tshirts training images -  707\n","number of shirts testing images -  21\n","number of tshirts testing images -  21\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jpnQDRaUOA2C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594567704716,"user_tz":-330,"elapsed":9115,"user":{"displayName":"Shalini Kumari","photoUrl":"https://lh5.googleusercontent.com/-f1p0Rlt5xtw/AAAAAAAAAAI/AAAAAAAAAPg/QAilL7XEoAo/s64/photo.jpg","userId":"00879105127542526832"}},"outputId":"62848c3c-8234-4a2b-c792-08e66823cd32"},"source":["model = Sequential()\n","\n","model.add(Conv2D(32,(3,3), padding = 'same',\n","                input_shape=(128, 128, 3)))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32,(3,3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","model.add(Conv2D(64,(3,3),padding = 'same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64,(3,3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dense(3))\n","model.add(Activation('softmax'))\n","#initiate RMSProp optimizer and configure parameters\n","opt = keras.optimizers.rmsprop(lr=0.0001,decay = 1e-6)\n","#let's create our model\n","model.compile(loss = 'categorical_crossentropy',optimizer = opt, metrics = ['accuracy'])\n","\n","print(model.summary())\n","model.fit_generator(training_set,epochs=20,validation_data=test_set)"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_9 (Conv2D)            (None, 128, 128, 32)      896       \n","_________________________________________________________________\n","activation_13 (Activation)   (None, 128, 128, 32)      0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 126, 126, 32)      9248      \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 126, 126, 32)      0         \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 63, 63, 32)        0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 63, 63, 64)        18496     \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 63, 63, 64)        0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 61, 61, 64)        36928     \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 61, 61, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 30, 30, 64)        0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 57600)             0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 512)               29491712  \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 3)                 1539      \n","_________________________________________________________________\n","activation_18 (Activation)   (None, 3)                 0         \n","=================================================================\n","Total params: 29,558,819\n","Trainable params: 29,558,819\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","67/67 [==============================] - 176s 3s/step - loss: 1.0378 - accuracy: 0.5012 - val_loss: 0.7687 - val_accuracy: 0.6825\n","Epoch 2/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.7008 - accuracy: 0.6902 - val_loss: 0.4380 - val_accuracy: 0.8413\n","Epoch 3/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.6010 - accuracy: 0.7317 - val_loss: 0.4596 - val_accuracy: 0.7778\n","Epoch 4/20\n","67/67 [==============================] - 176s 3s/step - loss: 0.5169 - accuracy: 0.7727 - val_loss: 0.2104 - val_accuracy: 0.9365\n","Epoch 5/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.4851 - accuracy: 0.7949 - val_loss: 0.1799 - val_accuracy: 0.8730\n","Epoch 6/20\n","67/67 [==============================] - 172s 3s/step - loss: 0.4264 - accuracy: 0.8043 - val_loss: 0.1894 - val_accuracy: 0.9206\n","Epoch 7/20\n","67/67 [==============================] - 177s 3s/step - loss: 0.3900 - accuracy: 0.8373 - val_loss: 0.1626 - val_accuracy: 0.9365\n","Epoch 8/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.3635 - accuracy: 0.8557 - val_loss: 0.1779 - val_accuracy: 0.9206\n","Epoch 9/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.3426 - accuracy: 0.8590 - val_loss: 0.1849 - val_accuracy: 0.9524\n","Epoch 10/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.2955 - accuracy: 0.8788 - val_loss: 0.1034 - val_accuracy: 0.9365\n","Epoch 11/20\n","67/67 [==============================] - 176s 3s/step - loss: 0.2832 - accuracy: 0.8854 - val_loss: 0.0326 - val_accuracy: 0.9524\n","Epoch 12/20\n","67/67 [==============================] - 172s 3s/step - loss: 0.2536 - accuracy: 0.9000 - val_loss: 0.1592 - val_accuracy: 0.9524\n","Epoch 13/20\n","67/67 [==============================] - 172s 3s/step - loss: 0.2517 - accuracy: 0.9000 - val_loss: 0.0795 - val_accuracy: 0.9524\n","Epoch 14/20\n","67/67 [==============================] - 172s 3s/step - loss: 0.2294 - accuracy: 0.9043 - val_loss: 0.0912 - val_accuracy: 0.9841\n","Epoch 15/20\n","67/67 [==============================] - 176s 3s/step - loss: 0.2195 - accuracy: 0.9114 - val_loss: 0.1735 - val_accuracy: 0.9524\n","Epoch 16/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.2124 - accuracy: 0.9109 - val_loss: 0.0796 - val_accuracy: 0.9683\n","Epoch 17/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.2064 - accuracy: 0.9118 - val_loss: 0.1076 - val_accuracy: 0.9524\n","Epoch 18/20\n","67/67 [==============================] - 176s 3s/step - loss: 0.1979 - accuracy: 0.9170 - val_loss: 0.0860 - val_accuracy: 0.9524\n","Epoch 19/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.1788 - accuracy: 0.9250 - val_loss: 0.1783 - val_accuracy: 0.9524\n","Epoch 20/20\n","67/67 [==============================] - 173s 3s/step - loss: 0.1708 - accuracy: 0.9302 - val_loss: 0.1776 - val_accuracy: 0.9524\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f1936575668>"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"7Wt5b1uDORfT","colab_type":"code","colab":{}},"source":["# plot the training loss and accuracy\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","N = 25\n","plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy on Image\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3oZfgAsOUKp","colab_type":"code","colab":{}},"source":["model.save('image_classification')\n","print('model saved')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fhnRW8cOd-G","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","classifier = load_model('image_classification')"],"execution_count":null,"outputs":[]}]}